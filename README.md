# Stable Diffusion Textâ€‘toâ€‘Image Generator

A clean and efficient **Gradio-based AI image generation application** that uses **Stable Diffusion v1.4** to convert natural language prompts into highâ€‘quality images. The project demonstrates core concepts of modern generative AI, including diffusion models, latent representations, guidance scaling, and styleâ€‘based prompt enhancement.

---

## Overview

This project provides an interactive UI built with **Gradio**, allowing users to:

* Enter text prompts
* Adjust **Guidance Scale** (prompt adherence)
* Modify **Inference Steps** (image refinement)
* Select artistic **Styles** (anime, watercolor, photo, videoâ€‘game, etc.)
* Generate multiple images simultaneously

The backend loads the preâ€‘trained **Stable Diffusion v1.4** model from Hugging Faceâ€™s Diffusers library and uses GPU acceleration when available.

---

##  Demo image

Below is a screenshot of the interface showcasing all available controls:

![Demo Screenshot](./demo.png)

---

##  Key Features

###  Style Customization

Choose from predefined artistic styles:

* **Anime** â€“ Cute, vibrant, Ghibli inspired visuals
* **Photo** â€“ Photorealistic, DSLR like imagery
* **Video Game** â€“ Unreal Engine style render with dramatic lighting
* **Watercolor** â€“ Soft, pastel, painterly textures
* **None** â€“ Pure prompt driven output

###  Guidance Scale

Controls how strongly the model follows your prompt.

* Low â†’ Creative & flexible
* High â†’ Accurate & promptâ€‘strict

### **Inference Steps**

Higher steps mean more detailed images but slower generation.

### **ğŸ“·Multiple Outputs**

Generate 1â€“4 images per prompt in a single run.

---

##  Model Architecture & Transfer Learning

### **Stable Diffusion v1.4**

The model is built on:

* **CLIP Text Encoder** â€“ Converts text to embeddings
* **UNet Denoiser** â€“ Iteratively removes noise to form the image
* **VAE Decoder** â€“ Converts latent space into final pixels
* **Diffusion Scheduler** â€“ Controls denoising steps

### **Transfer Learning Concept**

This project leverages *transfer learning* by using a preâ€‘trained Stable Diffusion model trained on millions of imageâ€“text pairs. Instead of training from scratch, we reuse and adapt the modelâ€™s learned latent representations to generate new images using prompt + style modifiers.

---

##  Project Structure

```
.
â”œâ”€â”€ Text_to_Image.ipynb
â”œâ”€â”€ demo.png
â””â”€â”€ README.md
```

---

## Running the Project

1. Install dependencies
2. Run all the cells
3. The app will open in your browser automatically using link.
4. There is no cost associated with it for generating any number of images as we are using transfer Learning not any API keys.

Note: If the code or notebook is not rendering or visible, please download the file to view or use it properly.

---

## ğŸ¤ Contributions

Pull requests are welcome! For suggestions or improvements, open an issue in the repository.
